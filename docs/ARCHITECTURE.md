# Content Loader ì•„í‚¤í…ì²˜ ì„¤ê³„

## ğŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜

Content LoaderëŠ” **ê³„ì¸µ ë¶„ë¦¬ ì•„í‚¤í…ì²˜**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

```
content-loader/
â”œâ”€â”€ main.py                    # CLI ì§„ì…ì 
â”œâ”€â”€ executor.py               # í†µí•© ì‹¤í–‰ê¸°
â”œâ”€â”€ settings.py               # ì „ì—­ ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ core/                     # ê³µí†µ ê¸°ëŠ¥ (ê¸°ë°˜ ë ˆì´ì–´)
â””â”€â”€ loaders/                  # êµ¬í˜„ ë ˆì´ì–´
    â”œâ”€â”€ slack/
    â”œâ”€â”€ confluence/
    â””â”€â”€ github/
```

## ğŸ¯ í•µì‹¬ ì„¤ê³„ ì›ì¹™

### 1. ê³„ì¸µ ë¶„ë¦¬ + ìŠ¤íŠ¸ë¦¬ë° (Layered + Streaming)

- **core/**: ê³µí†µ ê¸°ë°˜ ê¸°ëŠ¥ (BaseExecutor, Models, Utils)
- **loaders/**: êµ¬ì²´ì ì¸ ë°ì´í„° ì†ŒìŠ¤ë³„ êµ¬í˜„ì²´
- **ì˜ì¡´ì„± ë°©í–¥**: `loaders/` â†’ `core/` (ë‹¨ë°©í–¥)
- **ìŠ¤íŠ¸ë¦¬ë°**: AsyncGeneratorë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬

### 2. ë…ë¦½ì„± + ê²¬ê³ ì„± (Independence + Resilience)

- ê° loaderëŠ” ì™„ì „íˆ ë…ë¦½ì ìœ¼ë¡œ ê°œë°œ/ë°°í¬ ê°€ëŠ¥
- ìƒˆë¡œìš´ loader ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš”
- ì„¤ì •ê³¼ ì½”ë“œê°€ ë™ì¼í•œ ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜
- **í†µí•© ì¬ì‹œë„ ë¡œì§**ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ëŒ€ì‘

### 3. í™•ì¥ì„± + ì‹¬í”Œí•¨ (Extensibility + Simplicity)

- ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤(`BaseExecutor`) êµ¬í˜„ìœ¼ë¡œ ì¼ê´€ì„± ìœ ì§€
- í”ŒëŸ¬ê·¸ì¸ ë°©ì‹ìœ¼ë¡œ ìƒˆ loader ì¶”ê°€ ê°€ëŠ¥
- **ë³µì¡í•œ íŒ¨í„´ ë°°ì œ**, í•µì‹¬ ê¸°ëŠ¥ë§Œ êµ¬í˜„

## ğŸ”§ í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### **1. Core Layer (ê³µí†µ ê¸°ëŠ¥)**

```python
# core/base.py - í†µí•© ì‹¤í–‰ê¸° íŒ¨í„´
@dataclass
class DateRange:
    start: Optional[datetime] = None
    end: Optional[datetime] = None

    def includes(self, target_date: datetime) -> bool:
        if self.start and target_date < self.start:
            return False
        if self.end and target_date > self.end:
            return False
        return True

class BaseExecutor(ABC):
    """í†µí•© ì‹¤í–‰ê¸° - ìŠ¤íŠ¸ë¦¬ë° + ê²¬ê³ ì„±"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.retry_handler = SimpleRetryHandler()

    @abstractmethod
    async def fetch(self, date_range: DateRange) -> AsyncGenerator[Document, None]:
        """ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¬¸ì„œ ë¡œë“œ"""
        pass

    async def execute(self, date_range: Optional[DateRange] = None) -> AsyncGenerator[Document, None]:
        """ì‹¤í–‰ + ê¸°ë³¸ ì—ëŸ¬ ì²˜ë¦¬"""
        if not date_range:
            date_range = DateRange()

        async for document in self.retry_handler.execute_with_retry(
            lambda: self.fetch(date_range)
        ):
            yield document

# core/models.py - ê³µí†µ ë°ì´í„° ëª¨ë¸
@dataclass
class Document:
    id: str
    title: str
    text: str
    metadata: Dict[str, Any]
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None

# core/utils.py - ì‹¬í”Œí•œ ìœ í‹¸ë¦¬í‹°
class SimpleRetryHandler:
    """ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë¡œì§"""

    async def execute_with_retry(self, func_generator):
        for attempt in range(3):
            try:
                async for item in func_generator():
                    yield item
                break
            except (ConnectionError, TimeoutError) as e:
                if attempt < 2:
                    await asyncio.sleep(2 ** attempt)
                else:
                    raise

class SimpleMemoryManager:
    """ë°°ì¹˜ ë‹¨ìœ„ ë©”ëª¨ë¦¬ ê´€ë¦¬"""

    async def process_batch(self, documents_stream, batch_size=20):
        batch = []
        async for doc in documents_stream:
            batch.append(doc)
            if len(batch) >= batch_size:
                yield batch
                batch = []
        if batch:
            yield batch
```

### **2. Execution Layer (ì‹¤í–‰ ê³„ì¸µ) - ìŠ¤íŠ¸ë¦¬ë° ê¸°ë°˜**

```python
# executor.py - í†µí•© ì‹¤í–‰ê¸° (ìŠ¤íŠ¸ë¦¬ë°)
class LoaderExecutor:
    def __init__(self, settings: GlobalSettings):
        self.executors = {
            "slack": SlackExecutor(settings.slack),
            "github": GitHubExecutor(settings.github),
            "confluence": ConfluenceExecutor(settings.confluence)
        }
        self.memory_manager = SimpleMemoryManager()

    async def run_single_loader(self, loader_type: str, date_range: DateRange = None):
        """íŠ¹ì • loader ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰"""
        executor = self.executors[loader_type]

        # ìŠ¤íŠ¸ë¦¬ë° + ë°°ì¹˜ ì²˜ë¦¬
        async for batch in self.memory_manager.process_batch(
            executor.execute(date_range)
        ):
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë²¡í„°DB ì €ì¥
            await self._save_documents_batch(batch)

    async def run_all_loaders(self, date_range: DateRange = None):
        """ëª¨ë“  loader ë³‘ë ¬ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)"""
        tasks = []
        for loader_type in self.executors.keys():
            tasks.append(self.run_single_loader(loader_type, date_range))

        await asyncio.gather(*tasks, return_exceptions=True)
```

### **3. Configuration Layer (ì„¤ì • ê³„ì¸µ)**

```python
# settings.py - ì„¤ì • ê´€ë¦¬
class LoaderConfigManager:
    def load_loader_config(self, loader_name: str) -> dict:
        """loaderë³„ ì„¤ì • ë¡œë“œ"""
        config_dir = Path(f"loaders/{loader_name}/config")
        return self._load_with_env_override(config_dir)

    def load_loader_sources(self, loader_name: str) -> dict:
        """loaderë³„ ì†ŒìŠ¤ ì„¤ì • ë¡œë“œ"""
        # Slack: channels.yaml, GitHub: repositories.yaml, etc.
        pass
```

## ğŸ”„ ë°ì´í„° í”Œë¡œìš°

```mermaid
graph TD
    A[main.py] --> B[LoaderExecutor]
    B --> C[SlackLoader]
    B --> D[GitHubLoader]
    B --> E[ConfluenceLoader]

    C --> F[SlackClient]
    D --> G[GitHubClient]
    E --> H[ConfluenceClient]

    F --> I[Document Processing]
    G --> I
    H --> I

    I --> J[UnifiedChunker]
    J --> K[EmbeddingService]
    K --> L[Vector DB]
```

## ğŸ›¡ï¸ ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬

### 1. ì‹¬í”Œí•œ ì¬ì‹œë„ ë¡œì§

```python
class SimpleRetryHandler:
    """ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë¡œì§"""

    async def execute_with_retry(self, func_generator, max_retries=3):
        for attempt in range(max_retries):
            try:
                async for item in func_generator():
                    yield item
                break
            except (ConnectionError, TimeoutError, aiohttp.ClientError) as e:
                if attempt < max_retries - 1:
                    backoff_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    await asyncio.sleep(backoff_time)
                else:
                    raise
```

### 2. ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ë³µêµ¬ (ì¦ë¶„ ì—…ë°ì´íŠ¸)

```python
class CheckpointManager:
    """DateRange ê¸°ë°˜ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬"""

    async def save_progress(self, source_key: str, last_modified: datetime):
        """ë§ˆì§€ë§‰ ì²˜ë¦¬ ì‹œê°„ ì €ì¥"""
        await self.cache_client.set(
            f"checkpoint:{source_key}",
            last_modified.isoformat(),
            expire=86400*30  # 30ì¼ ë³´ê´€
        )

    async def get_last_checkpoint(self, source_key: str) -> Optional[datetime]:
        """ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ë¡œ DateRange êµ¬ì„±"""
        checkpoint = await self.cache_client.get(f"checkpoint:{source_key}")
        return datetime.fromisoformat(checkpoint) if checkpoint else None
```

## ğŸš€ ì„±ëŠ¥ ìµœì í™”

### 1. ìŠ¤íŠ¸ë¦¬ë° ë©”ëª¨ë¦¬ ê´€ë¦¬

```python
class SimpleMemoryManager:
    """ìŠ¤íŠ¸ë¦¬ë° ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬"""

    async def process_batch(self, documents_stream, batch_size=20):
        """ìŠ¤íŠ¸ë¦¬ë° + ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±"""
        batch = []
        async for doc in documents_stream:
            batch.append(doc)

            if len(batch) >= batch_size:
                yield batch
                batch = []
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                import gc; gc.collect()

        if batch:  # ë§ˆì§€ë§‰ ë°°ì¹˜
            yield batch
```

### 2. í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬

```python
class BaseExecutor:
    """ì»¤ì„œ ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜"""

    async def _paginate_fetch(self, initial_params: dict):
        """ì»¤ì„œ ê¸°ë°˜ìœ¼ë¡œ í˜ì´ì§€ë³„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        cursor = None

        while True:
            params = {**initial_params}
            if cursor:
                params['cursor'] = cursor

            response = await self._make_request(params)

            for item in response.get('items', []):
                yield item

            # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
            if not response.get('has_next_page'):
                break
            cursor = response.get('next_cursor')
```

### 3. ì—°ê²° í’€ ê´€ë¦¬

```python
class SimpleClient:
    """ì¬ì‹œë„ ë¡œì§ + ì—°ê²° ê´€ë¦¬"""

    def __init__(self, settings):
        self.semaphore = asyncio.Semaphore(settings.max_concurrent)
        self.retry_handler = SimpleRetryHandler()

    async def make_request(self, url: str, **kwargs):
        async with self.semaphore:
            # ì¬ì‹œë„ ë¡œì§ ì ìš©
            async for response in self.retry_handler.execute_with_retry(
                lambda: self._single_request(url, **kwargs)
            ):
                return response
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­

### 1. í—¬ìŠ¤ ì²´í¬

```python
@app.get("/health")
async def health_check():
    """ê¸°ë³¸ í—¬ìŠ¤ ì²´í¬"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/health/detailed")
async def detailed_health_check():
    """ìƒì„¸ í—¬ìŠ¤ ì²´í¬"""
    checks = {
        "redis": await check_redis_connection(),
        "embedding_service": await check_embedding_service(),
        "llm_service": await check_llm_service()
    }
    return {"status": "healthy" if all(checks.values()) else "unhealthy", "checks": checks}
```

### 2. ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
@dataclass
class SimpleMetrics:
    source_type: str
    source_key: str
    start_time: float
    documents_processed: int = 0
    errors_count: int = 0

    def success_rate(self) -> float:
        total = self.documents_processed + self.errors_count
        return self.documents_processed / total if total > 0 else 0.0

class MetricsCollector:
    def get_summary(self) -> dict:
        return {
            "total_sources": len(self.metrics),
            "sources": {k: {
                "duration": v.duration(),
                "documents": v.documents_processed,
                "success_rate": v.success_rate()
            } for k, v in self.metrics.items()}
        }
```

## ğŸ” ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 1. ì¸ì¦ ì •ë³´ ê´€ë¦¬

- ëª¨ë“  API í‚¤/í† í°ì€ **í™˜ê²½ë³€ìˆ˜**ë¡œ ê´€ë¦¬
- `.env` íŒŒì¼ ë° ë¯¼ê° ì •ë³´ëŠ” **gitì—ì„œ ì œì™¸**
- ë¡œê·¸ì— ì¸ì¦ ì •ë³´ **ë…¸ì¶œ ë°©ì§€**

### 2. API ì—°ê²° ê²€ì¦

```python
class ConnectionValidator:
    async def validate_all_connections(self) -> dict:
        """ì‹œì‘ ì‹œ ëª¨ë“  ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²° ê²€ì¦"""
        results = {}

        if self.settings.slack_token:
            results["slack"] = await self._validate_slack()
        if self.settings.github_app_id:
            results["github"] = await self._validate_github()

        return results

    async def _validate_slack(self) -> dict:
        """Slack ì—°ê²° ê²€ì¦ (auth.test í˜¸ì¶œ)"""
        try:
            client = AsyncWebClient(token=self.settings.slack_token)
            response = await client.auth_test()
            return {"status": "success", "user_id": response["user_id"]}
        except Exception as e:
            return {"status": "failed", "error": str(e)}
```

## ğŸ”„ í™•ì¥ ë°©ë²•

### ìƒˆë¡œìš´ Executor ì¶”ê°€

1. **ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±**

```
loaders/new_source/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ sources.yaml
â”œâ”€â”€ executor.py     # ì‹¤í–‰ê¸°
â”œâ”€â”€ client.py
â””â”€â”€ entities.py     # ë°ì´í„° ëª¨ë¸
```

2. **BaseExecutor êµ¬í˜„**

```python
from core.base import BaseExecutor, DateRange, Document

class NewSourceExecutor(BaseExecutor):
    def __init__(self, config: dict):
        super().__init__(config)
        self.client = NewSourceClient(config)

    async def fetch(self, date_range: DateRange) -> AsyncGenerator[Document, None]:
        """ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¬¸ì„œ ë¡œë“œ"""

        # ì¦ë¶„ ì—…ë°ì´íŠ¸
        params = self._build_query_params(date_range)

        # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
        async for item in self._paginate_fetch(params):
            document = self._item_to_document(item)
            yield document

    def _build_query_params(self, date_range: DateRange) -> dict:
        """DateRangeë¥¼ API íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜"""
        params = {}
        if date_range.start:
            params['modified_since'] = date_range.start.isoformat()
        if date_range.end:
            params['modified_until'] = date_range.end.isoformat()
        return params
```

3. **LoaderExecutorì— ë“±ë¡**

```python
# executor.py
self.executors = {
    "slack": SlackExecutor(settings.slack),
    "github": GitHubExecutor(settings.github),
    "confluence": ConfluenceExecutor(settings.confluence),
    "new_source": NewSourceExecutor(settings.new_source)  # ì¶”ê°€
}
```

## ğŸ¯ ê°œì„  ìš”ì•½

### âœ… ì ìš©ëœ í•µì‹¬ íŒ¨í„´ë“¤

1. **BaseExecutor íŒ¨í„´**: ì¼ê´€ëœ `fetch()` ì¸í„°í˜ì´ìŠ¤
2. **ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬**: `AsyncGenerator[Document, None]` ë°˜í™˜
3. **ê²¬ê³ í•œ ì¬ì‹œë„**: ì§€ìˆ˜ ë°±ì˜¤í”„ + HTTP ìƒíƒœì½”ë“œë³„ ì²˜ë¦¬
4. **DateRange ê¸°ë°˜**: ì¦ë¶„ ì—…ë°ì´íŠ¸ ìµœì í™”
5. **í˜ì´ì§€ë„¤ì´ì…˜**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ëŒ€ìš©ëŸ‰ ì²˜ë¦¬
6. **ë°°ì¹˜ ì²˜ë¦¬**: ìŠ¤íŠ¸ë¦¬ë°ê³¼ ê²°í•©í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬

### ğŸ¯ ì‹¬í”Œí•¨ ìœ ì§€

- **ë³µì¡í•œ Circuit Breaker ì œê±°** â†’ ì‹¬í”Œí•œ ì¬ì‹œë„ë§Œ
- **ìš”ì•½ ê¸°ëŠ¥ì€ ì˜µì…˜** â†’ ê¸°ë³¸ ê¸°ëŠ¥ì— ì§‘ì¤‘
- **ìµœì†Œí•œì˜ ì¸í„°í˜ì´ìŠ¤** â†’ BaseExecutor í•˜ë‚˜ë¡œ í†µì¼
- **ì„¤ì • ê¸°ë°˜ í™•ì¥** â†’ ì½”ë“œ ë³€ê²½ ìµœì†Œí™”

ì´ ì•„í‚¤í…ì²˜ëŠ” **ê²¬ê³ í•¨ê³¼ ì‹¬í”Œí•¨**ì„ ê²°í•©í•œ êµ¬ì¡°ë¡œ, í™•ì¥ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ëª¨ë‘ í™•ë³´í–ˆìŠµë‹ˆë‹¤.
